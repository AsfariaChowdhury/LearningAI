{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c99e8b4f-24bd-49e2-9567-0aed6d5359da",
   "metadata": {},
   "source": [
    "# 1. What constitutes a probability measure?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d079338c-1a2a-4327-b209-cd7fe9ee26bd",
   "metadata": {},
   "source": [
    "A *probability measure* (or *probability distribution*) $P$ on the sample space ($S$, <span style=\"font-family: 'cursive';\">S</span>) is a real-valued function defined on the collection of events that <span style=\"font-family: 'cursive';\">S</span> satisifes the following axioms:\n",
    "1. $P(A) >= 0$ for every event $A$\n",
    "2. $P(S) = 1$\n",
    "3. If ${A_i:i\\in I}$ is a countable, pairwise disjoint collection of events then \n",
    "$$P(\\bigcup_{i\\in I}A_i)=\\sum_{i\\in I}P(A_i)$$\n",
    "\n",
    "Source: https://stats.libretexts.org/Bookshelves/Probability_Theory/Probability_Mathematical_Statistics_and_Stochastic_Processes_(Siegrist)/02%3A_Probability_Spaces/2.03%3A_Probability_Measures#:~:text=satisfies%20certain%20axioms.-,Definition,P(S)%3D1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa67b0d-3bed-4121-bedf-8892b946c0e8",
   "metadata": {},
   "source": [
    "# 2. Independence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd13096-09b9-4f6c-bb53-aa99810e5c35",
   "metadata": {},
   "source": [
    "P(A,B) = P(A)P(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f192c0d0-fb82-4398-94dd-6450aa53a9b1",
   "metadata": {},
   "source": [
    "# 3. Conditional Probabilty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccbb145-33fc-447c-b4d7-5ae4ad4cbf47",
   "metadata": {
    "tags": []
   },
   "source": [
    "$$P(A|B) = \\frac{P(A,B)}{P(B)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f136f20-4d67-48ec-8c87-74f1bd7d0def",
   "metadata": {},
   "source": [
    "# 4. Random Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8f5eef-7ec2-4463-b3db-9eb908742369",
   "metadata": {},
   "source": [
    "A *random variable*, usually written *X*, is a variable whose possible values are numerical outcomes of a random phenomenon.\n",
    "\n",
    "Source: http://www.stat.yale.edu/Courses/1997-98/101/ranvar.htm#:~:text=Discrete%20Random%20Variables,then%20it%20must%20be%20discrete."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d3282e-c79e-452e-a3dc-cf746e32283e",
   "metadata": {},
   "source": [
    "## 4.1 Discrete Random Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6a718e-6f85-48c8-9481-e1f089699c93",
   "metadata": {},
   "source": [
    "A *discrete random variable* is one which may take on only a countable number of distinct values such as 0,1,2,3,4,........ Discrete random variables are usually (but not necessarily) counts. If a random variable can take only a finite number of distinct values, then it must be discrete. Examples of discrete random variables include the number of children in a family, the number of patients in a doctor's surgery, the number of defective light bulbs in a box of ten."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc37f38-f5ac-489c-916a-1d79d7bbc155",
   "metadata": {},
   "source": [
    "## 4.2 Continuous Random Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e6ad92-5df7-4269-a091-7acc78041175",
   "metadata": {},
   "source": [
    "A *continuous random variable* is one which takes an infinite number of possible values. Continuous random variables are usually measurements. Examples include height, weight, the amount of sugar in an orange, the time required to run a mile."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f915ed24-685f-4d1e-95cc-359776a8fa07",
   "metadata": {},
   "source": [
    "# 5. Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec1822d-822d-4f65-bd8c-3e1ec1f1c443",
   "metadata": {},
   "source": [
    "A language model uses machine learning to conduct a probability distribution over words used to predict the most likely next word in a sentence based on the previous entry. Language models learn from text and can be used for producing original text, predicting the next word in a text, speech recognition, optical character recognition and handwriting recognition.\n",
    "\n",
    "Source: https://builtin.com/data-science/beginners-guide-language-models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36b56f5-e6a7-4f67-ab17-a04b7151029e",
   "metadata": {},
   "source": [
    "# 6. Maximum Likelihood Estimation for Binomials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46b7cb7-e66e-4933-ae49-a070923e1ade",
   "metadata": {},
   "source": [
    "Let $y$ be the number of successes resulting from $n$ independent trials with unknown success probability $p$, such that $y$ follows a binomial distribution:\n",
    "$$y\\simeq Bin(n,p)$$\n",
    "Then, the maximum likelihood estimator of $p$ is\n",
    "$$\\hat{p} = \\frac{y}{n}$$\n",
    "\n",
    "Source: https://statproofbook.github.io/P/bin-mle.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816b11fb-af55-4062-b47e-53dd049f2585",
   "metadata": {},
   "source": [
    "# 7. Markov Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83458477-73b6-4f9b-b2c6-f62f78489ea4",
   "metadata": {},
   "source": [
    "**Markov chain** is a mathematical chain of events or states that describe the probability of the events that might occur in the future, based on the current state and not the previous states. It is a *stochastic model* that predicts the future based on the present state.\n",
    "\n",
    "In a Markov Chain, each state can be represented as a set of discrete steps. Each state has its own probability of transitioning to every other state. This may be represented by a weighted connected graph or by a transition matrix.\n",
    "\n",
    "Source: https://www.educative.io/answers/introduction-to-markov-chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f43092-e697-49c7-bdd3-6e1931da417c",
   "metadata": {},
   "source": [
    "# 8. Markov Assumption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb61500-1c7a-416d-9e87-8bc0ff30cc7f",
   "metadata": {},
   "source": [
    "The **Markov assumption**, a tenet named in honor of the Russian mathematician Andrey Markov, is a central idea in the sphere of probabilistic models, and more so in Markov processes. At its core, the Markov assumption proposes that the future state of a process relies solely on the current state by disregarding the journey to the current state. This attribute is commonly known as the \"memoryless\" aspect or \"absence of memory\" disregarding in Markov processes.\n",
    "\n",
    "Source: https://www.educative.io/answers/what-is-the-markov-assumption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9789f9-3e0f-4e20-b559-cf2617fc2f2f",
   "metadata": {},
   "source": [
    "# 9. Why is word sparcity an issue?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e72cd42-dae2-4497-9557-bd0fdddd2f32",
   "metadata": {},
   "source": [
    "Word sparsity can be an issue in natural language processing (NLP) and machine learning tasks for several reasons:\n",
    "\n",
    "1. **Data Scarcity**: In many NLP applications, you're working with large vocabularies or feature spaces. When building models based on text data, it's common to have a vast number of unique words or tokens in a corpus. However, not all words appear frequently in the data. This leads to data sparsity, where many words occur only a few times or even just once in your dataset. Sparse data can be challenging for statistical models because they lack sufficient examples to learn meaningful patterns.\n",
    "\n",
    "2. **Reduced Model Generalization**: Sparse data can lead to overfitting. When a model encounters rare words that it has only seen a few times during training, it may fit to the noise in the data rather than capturing the true underlying patterns. This can result in poor generalization to new, unseen data.\n",
    "\n",
    "3. **Increased Model Complexity**: Dealing with sparse data often requires more complex models. For instance, if you're using a bag-of-words representation where each unique word is a feature, you might end up with a high-dimensional feature space. This can increase model complexity and the computational resources required for training and inference.\n",
    "\n",
    "4. **Loss of Information**: Rare words or infrequent features may carry valuable information. In tasks like sentiment analysis or topic modeling, uncommon words can be strong indicators of sentiment or topic. When you discard or downweight these features due to their rarity, you lose potentially important information.\n",
    "\n",
    "5. **Efficiency Challenges**: Sparse data can be computationally inefficient to process and store. In large-scale NLP applications, it can lead to performance bottlenecks and increased memory requirements.\n",
    "\n",
    "To address issues related to word sparsity, NLP practitioners often use techniques like:\n",
    "\n",
    "- **Text Preprocessing**: Removing or reducing word sparsity by applying techniques like stemming, lemmatization, or removing stop words.\n",
    "- **Feature Engineering**: Using techniques like TF-IDF (Term Frequency-Inverse Document Frequency) to weight words based on their importance.\n",
    "- **Dimensionality Reduction**: Applying techniques like Principal Component Analysis (PCA) or Truncated SVD (Singular Value Decomposition) to reduce the dimensionality of sparse feature spaces.\n",
    "- **Word Embeddings**: Using word embeddings (e.g., Word2Vec, GloVe) to represent words as dense vectors in a lower-dimensional space. This not only reduces sparsity but also captures semantic relationships between words.\n",
    "- **Data Augmentation**: Expanding the dataset by generating more data through techniques like back-translation or synonym replacement.\n",
    "- **Transfer Learning**: Leveraging pre-trained models like BERT or GPT, which have learned from large corpora and can handle word sparsity more effectively.\n",
    "\n",
    "Addressing word sparsity is crucial for improving the performance of NLP models, especially in tasks where capturing subtle linguistic nuances is essential."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b4f886-549f-4fb3-8080-5e47f8d31dc2",
   "metadata": {},
   "source": [
    "# 10. Laplace Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da5c19a-7dc7-49b6-bf00-9aa7f32dac61",
   "metadata": {},
   "source": [
    "Laplace smoothing is a smoothing technique that handles the problem of zero probability in Naïve Bayes. Using Laplace smoothing, we can represent $P(w’|positive)$ as\n",
    "$$P(w'|positive)=\\frac{number\\, of\\, reviews\\, with\\, w'\\, and\\, y = positive+\\alpha}{N+\\alpha*K}$$\n",
    "Here,<br>\n",
    "$\\alpha$ represents the smoothing parameter<br>\n",
    "$K$ represents the number of dimensions (features) in the data, and<br>\n",
    "$N$ represents the number of reviews with y=positive<br>\n",
    "\n",
    "If we choose a value of alpha!=0 (not equal to 0), the probability will no longer be zero even if a word is not present in the training dataset.\n",
    "\n",
    "Source: https://towardsdatascience.com/laplace-smoothing-in-na%C3%AFve-bayes-algorithm-9c237a8bdece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12431920-6c96-4616-aa62-b6e60c8a4329",
   "metadata": {},
   "source": [
    "# 11. Good Turing Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652e6f6b-1d4b-4014-b1cb-e548edf52c15",
   "metadata": {},
   "source": [
    "Good-Turing smoothing is a technique used in natural language processing (NLP) and machine learning to estimate the probabilities of unseen or rare events, particularly in the context of language modeling and text classification. It was developed by I.J. Good and is a modification of Laplace smoothing, also known as add-one smoothing.\n",
    "\n",
    "The primary motivation behind Good-Turing smoothing is to address the \"zero-frequency problem.\" In language modeling, many words or n-grams may occur in a corpus only a few times, or not at all, making it difficult to estimate their probabilities accurately. Good-Turing smoothing helps by redistributing some of the probability mass from more frequent events to less frequent or unseen events.\n",
    "\n",
    "Here's an overview of how Good-Turing smoothing works:\n",
    "\n",
    "1. **Count the Frequency of Events**: First, you count the frequency of each event (e.g., words, n-grams) in your training data. Let's call these counts \"Nc,\" where \"c\" represents the count. For example, N1 is the count of events that occurred only once, N2 is the count of events that occurred twice, and so on.\n",
    "\n",
    "2. **Estimate the Probability of Unseen Events (Zero Counts)**: In cases where you have events with zero counts (unseen events), Good-Turing smoothing estimates their probability using the observed frequency of events with higher counts. It assumes that less frequent events follow the same distribution as more frequent events. The formula for estimating the probability of unseen events is:\n",
    "\n",
    "   P_unseen = (N1 + 1) / N\n",
    "\n",
    "   Where:\n",
    "   - P_unseen is the estimated probability of an unseen event.\n",
    "   - N1 is the count of events that occurred only once.\n",
    "   - N is the total number of events in the dataset.\n",
    "\n",
    "3. **Smooth Probabilities for Seen Events**: For events that have nonzero counts, you apply a smoothing formula to adjust their probabilities. The formula is based on the ratio of the count of events with a count of (c+1) to the count of events with a count of (c). This is used to redistribute some probability mass from higher-frequency events to lower-frequency ones. The smoothed probability is calculated as:\n",
    "\n",
    "   P_smoothed = (c+1) * (Nc+1) / Nc\n",
    "\n",
    "   Where:\n",
    "   - P_smoothed is the smoothed probability of an event with count \"c.\"\n",
    "   - c is the count of the event.\n",
    "   - Nc is the count of events with a count of \"c.\"\n",
    "   - Nc+1 is the count of events with a count of \"c+1.\"\n",
    "\n",
    "Good-Turing smoothing effectively reduces the probability mass assigned to frequent events and reallocates it to rare or unseen events, which can lead to more accurate probability estimates, especially for unseen events. This technique is commonly used in tasks like language modeling with n-grams, where you need to estimate the likelihood of word sequences that may not have been observed in your training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33d00c7-dc01-4367-8230-309800f4f0d4",
   "metadata": {},
   "source": [
    "# 12. LMs in topic modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffe634e-d40a-4e3d-8687-693dfc2f961b",
   "metadata": {},
   "source": [
    "In topic modeling, LMs (Language Models) can refer to a specific type of model used for estimating the probability of observing a sequence of words in a document or a set of documents. Language models play a crucial role in various aspects of topic modeling, including document classification, topic assignment, and text generation. Here's how LMs are used in topic modeling:\n",
    "\n",
    "1. **Document Classification**: Language models can be employed for classifying documents into predefined topics or categories. For instance, you might have a collection of news articles and want to categorize them into topics like \"politics,\" \"sports,\" or \"technology.\" LMs can calculate the probability of observing the words in each document given a specific topic model. The document is then assigned to the topic with the highest probability.\n",
    "\n",
    "2. **Topic Assignment**: In topic modeling techniques like Latent Dirichlet Allocation (LDA), documents are assumed to be generated based on a mixture of topics. LMs can be used to estimate the likelihood of a document being generated by a particular topic. This information is vital when assigning topics to documents in an unsupervised manner.\n",
    "\n",
    "3. **Text Generation**: LMs, especially neural language models like GPT-3, can be used to generate text based on a given topic. You can provide a topic or a set of keywords, and the language model will generate coherent text that is contextually relevant to the topic. This is useful for content generation, chatbots, and more.\n",
    "\n",
    "4. **Word Probability Estimation**: LMs can estimate the probability of observing specific words or phrases in a document or a collection of documents. This information can be used to identify important keywords or phrases associated with particular topics.\n",
    "\n",
    "5. **Model Evaluation**: LMs can help evaluate the quality of topic models. For instance, you can calculate the likelihood of observing your corpus of documents using an LDA model. The higher the likelihood, the better the model fits the data. LMs can also be used in perplexity calculations to assess how well a language model generalizes to unseen data.\n",
    "\n",
    "6. **Document Similarity**: LMs can be used to measure the similarity between documents based on the probability distributions of words. Documents with similar word probability distributions are likely to be related in terms of topics or content.\n",
    "\n",
    "7. **Summarization**: LMs can assist in generating document summaries. By identifying the most probable words or phrases in a document, you can create concise summaries that capture the key points or topics discussed.\n",
    "\n",
    "In the context of modern NLP, pre-trained language models like BERT, GPT-3, and others have been used for various topic modeling tasks due to their ability to capture complex language patterns and semantics. Researchers and practitioners often fine-tune these models on specific topic modeling tasks to achieve state-of-the-art results.\n",
    "\n",
    "In summary, language models play a multifaceted role in topic modeling, from document classification and topic assignment to text generation and model evaluation. They enable more accurate and sophisticated approaches to understanding and organizing text data into meaningful topics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6955954-2e82-44da-850d-32b02c278e34",
   "metadata": {},
   "source": [
    "# 13. Conditional Independence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48e0802-c4dc-4fe5-ac93-89d8e17c5d13",
   "metadata": {},
   "source": [
    "Two events $A$ and $B$ are **conditionally independent** given an event $C$ with $P(C)>0$ if\n",
    "$$P(A\\cap B|C) = P(A|C)P(B|C)$$\n",
    "\n",
    "Source: https://www.probabilitycourse.com/chapter1/1_4_4_conditional_independence.php"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe8fbd1-304b-48f3-88dc-b9951469dc2c",
   "metadata": {},
   "source": [
    "# 14. VIDEO Bayes Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7e7d88-3991-4484-b872-1ce74e022492",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=HZGCoVF3YvM&t=28s&ab_channel=3Blue1Brown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35da47a5-6a33-4c15-912b-160e6dd7ad63",
   "metadata": {},
   "source": [
    "# 15. Bayes Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf53a03-074e-43e5-9e16-bbbb6138052a",
   "metadata": {},
   "source": [
    "Let $E_1$, $E_2$, ... , $E_n$ be a set of events associated with a sample space $S$, where all the events $E_1$, $E_2$, ... , $E_n$ have nonzero probability of occurrence and they form a partition of $S$. Let $A$ be any event associated with $S$, then according to Bayes theorem,\n",
    "$$P(E_i|A)=\\frac{P(E_i)P(A|E_i)}{\\sum_{k=1}^{n}P(E_k)P(A|E_k)}$$\n",
    "for any $k=1,2,3,...,n$\n",
    "\n",
    "Source: https://byjus.com/maths/bayes-theorem/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4abed6-a566-473c-93cc-e5a3d056031b",
   "metadata": {},
   "source": [
    "# 16. Bayes Theorem in Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3babaa7c-6866-468b-a682-eb294a5f0168",
   "metadata": {},
   "source": [
    "**Medical diagnosis:** Bayes’ theorem is widely used in medical diagnosis, where the probability of a particular disease or condition given certain symptoms or test results is calculated. It helps physicians assess the likelihood of a disease based on prior knowledge and test outcomes.\n",
    "\n",
    "**Spam filtering:** In email spam filtering, Bayes’ theorem is used to classify incoming emails as spam or non-spam. It calculates the probability that an email is spam given the occurrence of certain words or patterns, based on a training dataset of known spam and non-spam emails.\n",
    "\n",
    "**Document categorization:** Bayes’ theorem is applied in text mining and natural language processing for document categorization tasks. It can help classify documents into predefined categories by calculating the probability of a document belonging to a category given its content or features.\n",
    "\n",
    "Source: https://medium.com/@evertongomede/applications-of-bayes-theorem-b3e95b4958de"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b376948b-9ea1-41b7-b556-77724d059321",
   "metadata": {},
   "source": [
    "# 17. Probability Density Function (PDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812a6452-f971-43c3-82ac-a285c870922c",
   "metadata": {},
   "source": [
    "The **probability density function (pdf)** of a continuous random variable $X$ with support $S$ is an integrable function $f(x)$ satisfying the following:\n",
    "1. $f(x)$ is positive everywhere in the support $S$, that is, $f(x)>0$, for all $x$ in $S$\n",
    "2. The area under the curve $f(x)$ in the support $S$ is 1, that is:\n",
    "$$\\int_{S}f(x)dx=1$$\n",
    "3. If $f(x)$ is the pdf of $x$, then the probability that $x$ belongs to $A$, where $A$ is some interval, is given by the integral of $f(x)$ over that integral, that is:\n",
    "$$P(X\\in A)=\\int_{A}f(x)dx$$\n",
    "\n",
    "Source: https://online.stat.psu.edu/stat414/lesson/14/14.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f94383-8551-4bee-9d5b-360421e1ebec",
   "metadata": {},
   "source": [
    "# 18. Common PDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f14130-6a49-49ce-9fe1-fa75be28df93",
   "metadata": {},
   "source": [
    "## 18.1 Normal Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865b7137-dd14-4fd8-87be-ce83dffb6693",
   "metadata": {},
   "source": [
    "In a normal distribution, data is symmetrically distributed with no skew. When plotted on a graph, the data follows a bell shape, with most values clustering around a central region and tapering off as they go further away from the center.\n",
    "\n",
    "Normal distributions are also called Gaussian distributions or bell curves because of their shape.\n",
    "\n",
    "Source: scribbr.com/statistics/normal-distribution/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a9121b-45fe-4638-a9e0-6989b570be66",
   "metadata": {},
   "source": [
    "## 18.2 Uniform Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082c1fe2-ca1a-4ba6-a3a9-bd4bdb78a11e",
   "metadata": {},
   "source": [
    "A uniform distribution, sometimes also known as a rectangular distribution, is a distribution that has constant probability.\n",
    "\n",
    "Source: https://mathworld.wolfram.com/UniformDistribution.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40279dd-89b2-4f0d-86ea-86e676d1da96",
   "metadata": {},
   "source": [
    "## 18.3 Exponential Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e612f069-5411-4a1a-9e4d-b7210e8ff7fa",
   "metadata": {},
   "source": [
    "The exponential distribution is a continuous probability distribution used to model the time elapsed before a given event occurs.\n",
    "\n",
    "Sometimes it is also called negative exponential distribution.\n",
    "\n",
    "Source: https://www.statlect.com/probability-distributions/exponential-distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5125ccd9-a45c-4947-99bc-5442f6393678",
   "metadata": {},
   "source": [
    "# 19. How does kernel density estimation work?, pp 116"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61444cbd-b1f0-4a11-89d5-6b26413b0833",
   "metadata": {},
   "source": [
    "The KDE algorithm takes a parameter, *bandwidth*, that affects how “smooth” the resulting curve is.\n",
    "\n",
    "The KDE is calculated by weighting the distances of all the data points for each location on the curve (produced by histogram-bins). If there are more points nearby, the estimate is higher, indicating that probability of seeing a point at that location.\n",
    "\n",
    "Changing the bandwidth changes the shape of the kernel: a lower bandwidth means only points very close to the current position are given any weight, which leads to the estimate looking squiggly; a higher bandwidth means a shallow kernel where distant points can contribute.\n",
    "\n",
    "The concept of weighting the distances of our observations from a particular point, $x$, can be expressed mathematically as follows:\n",
    "$$\\hat{f}(x)=\\sum_{observations}K(\\frac{x-observation}{bandwidth})$$\n",
    "The variable $K$ represents the kernel function. Using different kernel functions will produce different estimates.\n",
    "\n",
    "Source: https://mathisonian.github.io/kde/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5137b7-6541-4880-bdca-e72207dfcfad",
   "metadata": {},
   "source": [
    "# 20. Probability Mass Functions (pmf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cd55f3-aada-47c5-9ba5-614aced1839b",
   "metadata": {},
   "source": [
    "Let $X$ be a discrete random variable with range $R_X=\\{x_1,x_2,x_3,...\\}$ (finite or countably infinite). The function\n",
    "$$P_X(x_k)=P(X=x_k),\\;\\;\\;\\;for\\;k=1,2,3,...$$\n",
    "is called the *probability mass function (PMF)* of $X$.\n",
    "\n",
    "Source: https://www.probabilitycourse.com/chapter3/3_1_3_pmf.php"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166fe2b8-2227-4fba-b91b-e7553672089a",
   "metadata": {},
   "source": [
    "# 21. Common PMFs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64908f92-cf36-4680-9227-8500d044207a",
   "metadata": {},
   "source": [
    "## 21.1 Binomial Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a3a62e-df5e-4329-bc6c-004d5b202599",
   "metadata": {},
   "source": [
    "A **binomial distribution** can be thought of as simply the probability of a SUCCESS or FAILURE outcome in an experiment or survey that is repeated multiple times. The binomial is a type of distribution that has **two possible outcomes** (the prefix “bi” means two, or twice).\n",
    "1. The first variable in the binomial formula, $n$, stands for the number of times the experiment runs.\n",
    "2. The second variable, $p$, represents the probability of one specific outcome.\n",
    "***\n",
    "**Criteria for Binomial Distribution:**\n",
    "1. The number of observations or trials is fixed.\n",
    "2. Each observation or trial is independent.\n",
    "3. The probability of success (tails, heads, fail or pass) is exactly the same from one trial to another."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a3ebe6-118b-4f75-9b7f-e62d4021975d",
   "metadata": {},
   "source": [
    "## 21.2 Bernoulli Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d83318-cf74-4f21-ac87-f38489618157",
   "metadata": {},
   "source": [
    "Bernoulli distribution applies to events that have **one trial** and **two possible outcomes**. These are known as Bernoulli trials.\n",
    "\n",
    "Source: https://careerfoundry.com/en/blog/data-analytics/what-is-bernoulli-distribution/#:~:text=To%20recap%3A-,Bernoulli%20distribution%20is%20a%20discrete%20probability%20distribution,success)%20or%20tails%20(failure)%3F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509fcdff-554e-43eb-b22a-6e89c15c9c79",
   "metadata": {},
   "source": [
    "## 21.3 Discrete Uniform Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fa5c07-dfd3-4a33-803c-4906a967504c",
   "metadata": {},
   "source": [
    "A discrete uniform distribution is one that has a finite (or countably finite) number of random variables that have an equally likely chance of occurring. Examples of experiments that result in discrete uniform distributions are the rolling of a die or the selection of a card from a standard deck. For a fair, six-sided die, there is an equal probability $\\frac{1}{6}$ of rolling a 1, 2, 3, 4, 5, or 6. Similarly, a standard deck of cards has 52 different cards, so the probability of selecting any one card is $\\frac{1}{52}$. Also, in both cases, there are distinct outcomes (dice roll or cards), indicating the discrete nature of the events.\n",
    "\n",
    "More specifically, let x be a discrete random variable having n values over the interval $[a,b]$; x has a discrete uniform distribution if its probability mass function (pmf) is defined by:\n",
    "$$f(x)=\\frac{1}{n},\\;\\;\\;\\;x=1,2,3,...,n$$"
   ]
  },
  {
   "attachments": {
    "dd5e66a3-7034-45ce-a75b-9781bce02dd4.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "fc3211c4-93b4-416a-9227-559772afe5f4",
   "metadata": {},
   "source": [
    "![image.png](attachment:dd5e66a3-7034-45ce-a75b-9781bce02dd4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f802506-9cb2-4039-9aec-037c27f30251",
   "metadata": {},
   "source": [
    "Source: https://www.math.net/uniform-distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775c8f51-498c-4b45-be03-1d5e60bb7cd0",
   "metadata": {},
   "source": [
    "## 21.4 Geometric Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5983c47b-4ba7-4ffc-9305-b81a921b0873",
   "metadata": {},
   "source": [
    "The **geometric distribution** is a probability distribution that models the number of trials required to achieve the first success in a sequence of independent Bernoulli trials, where each trial has a constant probability of success.\n",
    "\n",
    "A geometric distribution can have an indefinite number of trials until the first success is obtained.\n",
    "\n",
    "Source: https://www.cuemath.com/geometric-distribution-formula/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9626f9-b40c-4cae-84b5-c9db83ba01a5",
   "metadata": {},
   "source": [
    "# 22. Cumulative Distribution Function (CDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c454d61-e2ed-4786-863b-c30222b8c222",
   "metadata": {},
   "source": [
    "A cumulative distribution function (CDF) describes the probabilities of a random variable having values less than or equal to $x$. It is a cumulative function because it sums the total likelihood up to that point. Its output always ranges between 0 and 1.\n",
    "$$CDF(x) = P(X ≤ x)$$\n",
    "Where $X$ is the random variable, and $x$ is a specific value. The CDF gives us the probability that the random variable $X$ is less than or equal to $x$. These functions are non-decreasing. As $x$ increases, the likelihood can either increase or stay constant, but it can not decrease.\n",
    "\n",
    "Both probability density functions (PDFs) and cumulative distribution functions provide likelihoods for random variables. However, PDFs calculate probability densities for $x$, while CDFs give the chances for $≤ x$.\n",
    "\n",
    "Cumulative distribution functions are excellent for providing probabilities that the next observation will be less than or equal to the value you specify. This ability can help you make decisions that incorporate uncertainty.\n",
    "\n",
    "Additionally, these cumulative probabilities are equivalent to percentiles. A cumulative probability of 0.80 is the same as the $80^{th}$ percentile. So, CDFs are great for finding percentiles.\n",
    "\n",
    "Source: https://statisticsbyjim.com/probability/cumulative-distribution-function-cdf/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21974f87-7b57-4878-8ba0-e76a94d6adb3",
   "metadata": {},
   "source": [
    "## 22.1 How to Transform a PDF/PMF to CDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526995f9-b653-454a-b0e0-c100b9656454",
   "metadata": {},
   "source": [
    "### 22.1.1 PDF to CDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25604579-8fa3-41c3-8f3b-969941983bdb",
   "metadata": {},
   "source": [
    "1. When $x<0$, $F(x)=0$\n",
    "2. For $x<when\\_function\\_argument\\_changes$,\n",
    "$$F(x)=F(0)+\\int_0^x(argument)dx$$\n",
    "3. For each x-range, different F(x) -> piecewise.\n",
    "4. $F(last\\_x)=1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdbc190-f696-4556-b4b3-a99b2c90338a",
   "metadata": {},
   "source": [
    "https://youtu.be/Zg_OGcSJYHI?si=XZnkkhzhxzAywcbD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed3249b-4ad1-4c22-8d12-ffaebb20d0d1",
   "metadata": {},
   "source": [
    "### 22.1.2 PMF to CDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457fd5e0-9106-4185-890d-411e76179711",
   "metadata": {},
   "source": [
    "https://youtu.be/1TRYf4_ZFT8?si=k5pGid37fChnLWnY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1f85a6-61bf-46a5-81a1-a1ba0a7c4e6d",
   "metadata": {},
   "source": [
    "# 23. How to derive the parameter estimate from the likehood function?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bf88f2-da22-49d0-99bf-89e2dc803d2b",
   "metadata": {},
   "source": [
    "Read full: \n",
    "1. https://blog.paperspace.com/maximum-likelihood-estimation-parametric-classification/\n",
    "2. https://towardsdatascience.com/probability-concepts-explained-maximum-likelihood-estimation-c7b4342fdbb1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a1a1f5-d923-4907-8986-bec91dfb8d8a",
   "metadata": {},
   "source": [
    "1. **Probability Function:** Find the probability function that makes a prediction.\n",
    "2. **Likelihood:** Based on the probability function, derive the likelihood of the distribution.\n",
    "3. **Log-Likelihood:** Based on the likelihood, derive the log-likelihood.\n",
    "4. **Maximum Likelihood Estimation:** Find the maximum likelihood estimation of the parameters that form the distribution.\n",
    "5. **Estimated Distribution:** Plug the estimated parameters into the probability function of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349a9c70-364c-4980-afb0-5601e36a2285",
   "metadata": {},
   "source": [
    "# 24. MLE over a Continuous Random Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d900239c-e4d4-4263-a3f4-b56a70f0baf7",
   "metadata": {},
   "source": [
    "For **Gaussian distribution**:\n",
    "1. MLE of mean:\n",
    "$$m=\\frac{\\sum_{t=1}^{N}x^t}{N}$$\n",
    "2. MLE of variance:\n",
    "$$s^2=\\frac{\\sum_{t=1}^{N}(x^t-m)^2}{N}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86ed496-4c29-426f-a2d3-a5ca4b92591f",
   "metadata": {},
   "source": [
    "# 25. Mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edc5863-bc34-4f2b-87ba-7f65da96a461",
   "metadata": {},
   "source": [
    "The **mean** is the average of a data set. It is the center of a probability distribution.\n",
    "\n",
    "Source: https://www.statisticshowto.com/probability-and-statistics/statistics-definitions/mean-median-mode/#mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb1a3ab-5b38-4218-8c5a-64078d6d65bd",
   "metadata": {},
   "source": [
    "# 26. Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594e5dba-2add-4ba3-b8f7-15b67f2df928",
   "metadata": {},
   "source": [
    "The Standard Deviation is a measure of how spread out numbers are.\n",
    "\n",
    "Source: https://www.mathsisfun.com/data/standard-deviation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7d7c82-4f88-4fc4-a3a1-484b34a6b26c",
   "metadata": {},
   "source": [
    "# 27. Expectation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce6987d-7542-4f9e-a530-874592a88c60",
   "metadata": {},
   "source": [
    "Expectation is summation or integration of a possible values from a random variable.\n",
    "\n",
    "Source: https://www.statisticssolutions.com/free-resources/directory-of-statistical-analyses/mathematical-expectation/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb47d96d-859d-45ad-95bf-8f1ba9c3aa1a",
   "metadata": {},
   "source": [
    "## 27.1 Expectation of Discrete Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a10c21-349b-48da-9f9a-0e0a82d91cc6",
   "metadata": {},
   "source": [
    "$$E(X)=\\sum xP(X=x)$$\n",
    "Source: https://nzmaths.co.nz/category/glossary/expected-value-discrete-random-variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af700bce-a155-492f-8229-df166620fa8c",
   "metadata": {},
   "source": [
    "## 27.2 Expectation of Continuous Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efbc64d-e1d0-4e1c-ad49-aca00b1aa7f5",
   "metadata": {},
   "source": [
    "$$E(X)=\\int_{-\\infty}^{\\infty}x.f(x)dx$$\n",
    "Source: https://dlsun.github.io/probability/ev-continuous.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3753ff97-a34a-405d-9cfa-621cbf759700",
   "metadata": {},
   "source": [
    "# 28. The Scientific Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273248ca-5346-40b4-a731-3a2b1a5892a8",
   "metadata": {},
   "source": [
    "1. Ask a Question\n",
    "2. Do Background Research\n",
    "3. Construct a Hypothesis\n",
    "4. Test Your Hypothesis by Doing an Experiment\n",
    "5. Analyze Your Data and Draw a Conclusion\n",
    "6. Communicate Your Results\n",
    "\n",
    "Source: https://www.sciencebuddies.org/science-fair-projects/science-fair/steps-of-the-scientific-method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df68cbb-df95-4cb3-988e-0d2024ba8480",
   "metadata": {},
   "source": [
    "# 29. Null Hypotheses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09598f29-c6d6-4a20-a4bb-9b47d8b78bd6",
   "metadata": {},
   "source": [
    "This can be thought of as the implied hypothesis. “Null” meaning “nothing.”  This hypothesis states that there is no difference between groups or no relationship between variables. The null hypothesis is a presumption of status quo or no change.\n",
    "\n",
    "Source: https://resources.nu.edu/statsresources/hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe62d83-3f4a-4b4a-bd13-4ee8f4fdaa30",
   "metadata": {},
   "source": [
    "# 30. Alternative Hypotheses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b584c26b-e6c3-47a2-b447-6fc2abd944dd",
   "metadata": {},
   "source": [
    "This is also known as the claim. This hypothesis should state what you expect the data to show, based on your research on the topic. This is your answer to your research question.\n",
    "\n",
    "Source: https://resources.nu.edu/statsresources/hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03ab057-fb19-47ad-893e-00bb602e6f7b",
   "metadata": {},
   "source": [
    "# 31. Defining a rejection region based on hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dea084-ba6a-4838-8405-b51e4afc2d39",
   "metadata": {},
   "source": [
    "## 31.1 Left-tailed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd40f6b1-ad54-4987-be29-a9038a45e307",
   "metadata": {},
   "source": [
    "$$P(Z\\leq z^*)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23dd30d-f522-4d63-9085-618e71e67c3b",
   "metadata": {},
   "source": [
    "## 31.2 Right-tailed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb32549-acd3-48ef-8c17-41c8ecbfb257",
   "metadata": {},
   "source": [
    "$$P(Z\\geq z^*)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e451cdd5-02ce-447d-8d20-01fbb251d53b",
   "metadata": {},
   "source": [
    "## 31.3 Two-tailed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977b697e-2df0-4d48-8dd4-865c72bb9567",
   "metadata": {},
   "source": [
    "$$2\\times P(Z\\geq |z^*|)$$\n",
    "\n",
    "Source: https://online.stat.psu.edu/stat500/lesson/6a/6a.4/6a.4.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceed1723-3e5c-4524-ae35-272570239452",
   "metadata": {},
   "source": [
    "# 32. T-tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5fefb2-b8e4-4285-acfb-8cd71e3e6d78",
   "metadata": {},
   "source": [
    "A **t test** is a statistical test that is used to compare the means of two groups. It is often used in hypothesis testing to determine whether a process or treatment actually has an effect on the population of interest, or whether two groups are different from one another.\n",
    "\n",
    "Source: https://www.scribbr.com/statistics/t-test/#:~:text=A%20t%20test%20is%20a,are%20different%20from%20one%20another."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fd68fd-b1d9-43d8-bc7e-c98a5cdff2ef",
   "metadata": {},
   "source": [
    "# 33. Degrees of Freedom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d316e2-fc57-45cd-b4d5-390ad728c07f",
   "metadata": {},
   "source": [
    "In inferential statistics, you estimate a parameter of a population by calculating a statistic of a sample. The number of independent pieces of information used to calculate the statistic is called the **degrees of freedom**.\n",
    "\n",
    "Source: https://www.scribbr.com/statistics/degrees-of-freedom/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73497f7-192b-4476-8381-a3cf714a16a9",
   "metadata": {},
   "source": [
    "# 34. Error Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409d1cd5-6236-45c2-99fc-678512a3fef7",
   "metadata": {},
   "source": [
    "**Type I error** is a false positive conclusion, while a **Type II error** is a false negative conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e408866-23d7-4808-aaa0-71aa2ab928f9",
   "metadata": {},
   "source": [
    "# Latex Styling Used in this Markdown Document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da61673-dadc-498d-8f04-098d39dbf962",
   "metadata": {},
   "source": [
    "1. Set notation, union: https://latex-tutorial.com/union-latex/\n",
    "2. Summation: https://www.physicsread.com/latex-summation/\n",
    "3. Set notations: https://www.geeksforgeeks.org/set-notations-in-latex/\n",
    "4. Equations: https://www.fabriziomusacchio.com/blog/2021-08-10-How_to_use_LaTeX_in_Markdown/\n",
    "5. Similarly Equivalent: https://www.overleaf.com/learn/latex/List_of_Greek_letters_and_math_symbols\n",
    "6. Line break: https://www.markdownguide.org/basic-syntax/#:~:text=To%20create%20a%20line%20break,spaces%2C%20and%20then%20type%20return.\n",
    "7. Spacing in math equations: http://www.emerson.emory.edu/services/latex/latex_119.html\n",
    "8. Integrals: https://www.overleaf.com/learn/latex/Questions/Writing_integrals_in_LaTeX#:~:text=It%27s%20very%20easy%20in%20LaTeX%20to%20write%20an,%24%24int_%20%7B0%7D%5E%20%7Bpi%7Dx%5E2%20%2Cdx%24%24%20Basic%20LaTeX%2015%3A%20Integrals\n",
    "9. Infinity: https://latex-tutorial.com/infinity-latex/#Infinity-in-LaTeX\n",
    "10. Multiplication: https://www.math-linux.com/latex-26/faq/latex-faq/article/latex-symbol-multiply"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "itil",
   "language": "python",
   "name": "itil"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
